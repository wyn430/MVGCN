{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import open3d as o3d\n",
    "from pyntcloud import PyntCloud \n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN, OPTICS, SpectralCoclustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import torch\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##estimate statistics for normal surface\n",
    "noise_std = 0\n",
    "k_n = 50\n",
    "sigma_list = []\n",
    "data_folder = './Surface_Defects_pcd_extend_2000_estnorm_noise0001/'\n",
    "filenames = json.load(open(data_folder + 'train_files.txt', 'r'))\n",
    "\n",
    "for file in filenames:\n",
    "    if file.split('/')[1] == 'normal':\n",
    "        data = np.loadtxt(data_folder + file.split('/')[1] + '/' + file.split('/')[2], delimiter = ',')\n",
    "        point_cloud = data[:,:3]\n",
    "        point_cloud_noise = point_cloud + noise_std*np.random.randn(point_cloud.shape[0], point_cloud.shape[1])\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud_noise)\n",
    "        pcd1 = PyntCloud.from_instance(\"open3d\", pcd)\n",
    "\n",
    "        # find neighbors\n",
    "        kdtree_id = pcd1.add_structure(\"kdtree\")\n",
    "        k_neighbors = pcd1.get_neighbors(k=k_n, kdtree=kdtree_id) \n",
    "\n",
    "        # calculate eigenvalues\n",
    "        ev = pcd1.add_scalar_field(\"eigen_values\", k_neighbors=k_neighbors)\n",
    "\n",
    "        x = pcd1.points['x'].values \n",
    "        y = pcd1.points['y'].values \n",
    "        z = pcd1.points['z'].values \n",
    "\n",
    "        e1 = pcd1.points['e3('+str(k_n+1)+')'].values\n",
    "        e2 = pcd1.points['e2('+str(k_n+1)+')'].values\n",
    "        e3 = pcd1.points['e1('+str(k_n+1)+')'].values\n",
    "\n",
    "        sum_eg = np.add(np.add(e1,e2),e3)\n",
    "        sigma = np.divide(e1,sum_eg)\n",
    "        sigma_list.append(sigma)\n",
    "\n",
    "sigma_arr = np.concatenate(sigma_list, axis = 0)            \n",
    "normal_mean = sigma_arr.mean()\n",
    "normal_std = sigma_arr.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_folder = glob(\"./Surface_Defects_pcd_extend_2000_estnorm_noise0001/*/\")\n",
    "root = \"./Surface_Defects_pcd_extend_2000_estnorm_noise0001/\"\n",
    "files = []\n",
    "folders = ['raised', 'dent', 'crack']\n",
    "thresh = normal_mean + 1.282 * normal_std ##80% CI\n",
    "for cate in cate_folder:\n",
    "      \n",
    "    filename = os.listdir(cate)\n",
    "\n",
    "    for file in filename:\n",
    "\n",
    "        if file.split('.')[-1] == 'txt':\n",
    "            \n",
    "            \n",
    "            data = np.loadtxt(cate + file, delimiter = ',')\n",
    "            point_cloud = data[:,:3]\n",
    "            point_cloud_noise = point_cloud + noise_std*np.random.randn(point_cloud.shape[0], point_cloud.shape[1])\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(point_cloud_noise)\n",
    "\n",
    "            pcd1 = PyntCloud.from_instance(\"open3d\", pcd)\n",
    "\n",
    "            # define hyperparameters\n",
    "            \n",
    "            # thresh = 0.0336\n",
    "            # find neighbors\n",
    "            kdtree_id = pcd1.add_structure(\"kdtree\")\n",
    "            k_neighbors = pcd1.get_neighbors(k=k_n, kdtree=kdtree_id) \n",
    "\n",
    "            # calculate eigenvalues\n",
    "            ev = pcd1.add_scalar_field(\"eigen_values\", k_neighbors=k_neighbors)\n",
    "\n",
    "            x = pcd1.points['x'].values \n",
    "            y = pcd1.points['y'].values \n",
    "            z = pcd1.points['z'].values \n",
    "\n",
    "            e1 = pcd1.points['e3('+str(k_n+1)+')'].values\n",
    "            e2 = pcd1.points['e2('+str(k_n+1)+')'].values\n",
    "            e3 = pcd1.points['e1('+str(k_n+1)+')'].values\n",
    "\n",
    "            sum_eg = np.add(np.add(e1,e2),e3)\n",
    "            sigma = np.divide(e1,sum_eg)\n",
    "\n",
    "            # visualize the edges\n",
    "            sigma[sigma>thresh] = 1\n",
    "            sigma[sigma<=thresh] = 0\n",
    "            \n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(10))\n",
    "            pcd.orient_normals_consistent_tangent_plane(k=10)\n",
    "            norms = np.asarray(pcd.normals)\n",
    "            data[:,:3] = point_cloud_noise\n",
    "            data[:,6:] = norms\n",
    "            #fig = plt.figure()\n",
    "            #ax = fig.add_subplot(111, projection='3d')\n",
    "            np.savetxt(cate + file.split('.')[0] + '.txt', data, delimiter=',')\n",
    "            if cate.split('/')[-2] in folders:\n",
    "                np.savez(cate + file.split('.')[0] + '.npz', data = sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
